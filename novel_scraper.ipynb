{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import re\n",
    "from bs4 import BeautifulSoup\n",
    "import time\n",
    "import random\n",
    "from ebooklib import epub #http://docs.sourcefabric.org/projects/ebooklib/en/latest/tutorial.html#creating-epub\n",
    "from IPython.display import display, clear_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class Webpage:\n",
    "    def __init__(self, url, base_url):\n",
    "        self.url = url\n",
    "        self.base_url = base_url\n",
    "        self.soup = BeautifulSoup(requests.get(self.url, headers).content)\n",
    "        \n",
    "        self.extract_webpage()\n",
    "        self.extract_content()\n",
    "        \n",
    "    def extract_webpage(self):\n",
    "        next_url = self.soup.find('a', string=re.compile(css_nexttext))['href']\n",
    "        self.next_url = base_url + next_url\n",
    "        \n",
    "        \"\"\"soup.find('span', class_='shuming')\"\"\"\n",
    "        booktitle = self.soup.find(**css_booktitle).text\n",
    "        self._booktitle = self._clean_text(booktitle)\n",
    "        self._add_booktitle = ''\n",
    "        \n",
    "        \"\"\"soup.find('h1', id='timu')\"\"\"\n",
    "        try:\n",
    "            author = self.soup.find(**css_author).text\n",
    "            self.author = self._clean_text(author)\n",
    "        except:\n",
    "            self.author = ''\n",
    "        \n",
    "        \"\"\"soup.find('h1', id='timu')\"\"\"\n",
    "        chaptitle = self.soup.find(**css_chaptitle).text\n",
    "        self.chaptitle = self._clean_text(chaptitle)\n",
    "        \n",
    "    def extract_content(self):\n",
    "        \"\"\"soup.find('h1', id='timu')\"\"\"\n",
    "        # find all 'p'\n",
    "        # content = self.soup.find_all(**css_content)\n",
    "        # content = [x.get_text() for x in content]\n",
    "        # content = '\\n'.join(content)\n",
    "        content = self.soup.find('div', class_=re.compile('cont')).get_text('\\n')\n",
    "        # print(webpage.soup.find('div', class_=re.compile('cont')).get_text(\"\\n\"))\n",
    "        \n",
    "        # clean\n",
    "        content = content.strip()\n",
    "        content = content.replace('\\u3000', '\\n')\n",
    "        content = content.replace('\\xa0', '\\n')\n",
    "        content = content.replace('<br/>', '\\n')\n",
    "        \n",
    "        content = re.sub(r'\\n+', '\\n', content)\n",
    "        content = '\\t'.join(('\\n'+content.lstrip()).splitlines(keepends=True))\n",
    "\n",
    "        self._content = content\n",
    "        \n",
    "    @property\n",
    "    def booktitle(self):\n",
    "        return self._booktitle + self._add_booktitle\n",
    "    \n",
    "    @property\n",
    "    def add_booktitle(self):\n",
    "        return self._add_booktitle\n",
    "        \n",
    "    @add_booktitle.setter\n",
    "    def add_booktitle(self, add_booktitle):\n",
    "        self._add_booktitle = add_booktitle\n",
    "        \n",
    "    @property\n",
    "    def content(self):\n",
    "        # add chaptitle\n",
    "        chaptitle = self.chaptitle\n",
    "        content = self._content\n",
    "        \n",
    "        # print\n",
    "        t = time.localtime()\n",
    "        current_time = time.strftime(\"%H:%M\", t)\n",
    "        content_update_info = f\"{current_time}  {chaptitle} {len(content)}\"\n",
    "        try:\n",
    "            content_display.update(content_update_info)\n",
    "        except:\n",
    "            print(content_update_info)\n",
    "        \n",
    "        # add chaptitle to content\n",
    "        content = chaptitle + '\\n' + content\n",
    "        # html encode\n",
    "        content = content.replace('\\n', '<br>')\n",
    "        content = content.replace('\\t', '&emsp;')\n",
    "        return content\n",
    "\n",
    "    def _clean_text(self, text):\n",
    "        text = text.replace('小說', '')\n",
    "        text = text.replace('作者', '')\n",
    "        text = text.replace('：', ' ')\n",
    "        text = text.replace(':', ' ')\n",
    "        text = re.sub(r' +', ' ', text)\n",
    "        text = text.strip()\n",
    "        return text\n",
    "    \n",
    "class Book:\n",
    "    def __init__(self, first_webpage, language='zh'):\n",
    "        self.booktitle = first_webpage.booktitle\n",
    "        self.author = first_webpage.author\n",
    "        print('Booktitle:\\t', self.booktitle)\n",
    "        print('Author:\\t\\t', self.author)\n",
    "            \n",
    "        self.language = language\n",
    "        # print current chapter\n",
    "        global content_display\n",
    "        content_display = display('Getting chapter content...', display_id=True)\n",
    "        \n",
    "        self.book = self._create_epub()\n",
    "\n",
    "        # toc\n",
    "        self.toc = []\n",
    "        self.spine = []\n",
    "    \n",
    "    def _create_epub(self):\n",
    "        # define book\n",
    "        book = epub.EpubBook()\n",
    "        book.set_title(self.booktitle)\n",
    "        book.set_language(self.language)\n",
    "        if self.author: book.add_author(self.author)\n",
    "        return book\n",
    "    \n",
    "    def add_chap(self, webpage):\n",
    "        chap = self._create_epub_chap(webpage)\n",
    "        \n",
    "        # add chap to book\n",
    "        self.book.add_item(chap)\n",
    "        self.spine.append(chap)\n",
    "        # create toc\n",
    "        link = epub.Link(chap.file_name, chap.title, chap.id)\n",
    "        self.toc.append(link)\n",
    "        \n",
    "    def _create_epub_chap(self, webpage):\n",
    "        chaptitle = webpage.chaptitle\n",
    "        chap = epub.EpubHtml(title=chaptitle, file_name=chaptitle + '.xhtml')\n",
    "        chap.set_content(webpage.content)\n",
    "        return chap\n",
    "\n",
    "    def save(self):\n",
    "        book = self.book\n",
    "        # toc\n",
    "        toc = tuple(self.toc)\n",
    "        book.toc = toc\n",
    "\n",
    "        # add default NCX and Nav file\n",
    "        book.add_item(epub.EpubNcx())\n",
    "        book.add_item(epub.EpubNav())\n",
    "\n",
    "        # spine = tuple(spine)\n",
    "        book.spine = ['nav', *self.spine]\n",
    "\n",
    "        # write to the file\n",
    "        epub.write_epub('book/' + self.booktitle + '.epub', book, {})\n",
    "        print('saving {}...'.format(self.booktitle))\n",
    "        print('-------')\n",
    "    \n",
    "\"\"\"\n",
    "utils function\n",
    "\"\"\"    \n",
    "def run_test():\n",
    "    webpage = Webpage(url, base_url)\n",
    "    print('Booktitle:\\t', webpage.booktitle)\n",
    "    print('Author:\\t\\t', webpage.author)\n",
    "    print('Chap:\\t\\t', webpage.chaptitle)\n",
    "    print('Content length:\\t', end=' ')\n",
    "    webpage.content\n",
    "    print('Next url:\\t', webpage.next_url)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "page_limit = 0\n",
    "vol_break = 1000\n",
    "# https://tw.uukanshu.com/b/16893/52390.html\n",
    "url = \"\"\"\n",
    "https://tw.uukanshu.com/b/62531/1389.html\n",
    "\"\"\"\n",
    "url = url.strip()\n",
    "base_url = 'https://tw.uukanshu.com'\n",
    "\n",
    "# css\n",
    "css_booktitle    = {'name': 'span', 'class_': 'shuming'}\n",
    "css_author       = {'name': 'span', 'class_': 'author'}\n",
    "css_chaptitle    = {'name': 'h1', 'id': 'timu'}\n",
    "css_content      = {'name': 'p'}\n",
    "css_nexttext     = '下一章'\n",
    "\n",
    "headers = {\n",
    "    'Access-Control-Allow-Origin': '*',\n",
    "    'Access-Control-Allow-Methods': 'GET',\n",
    "    'Access-Control-Allow-Headers': 'Content-Type',\n",
    "    'Access-Control-Max-Age': '3600',\n",
    "    'User-Agent': 'Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:52.0) Gecko/20100101 Firefox/52.0'\n",
    "    }\n",
    "\n",
    "run_test()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save book"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "first_webpage = Webpage(url, base_url)\n",
    "book = Book(first_webpage)\n",
    "\"\"\"\n",
    "start scraping\n",
    "\"\"\"\n",
    "cnt = 0\n",
    "while cnt < page_limit or page_limit == 0:\n",
    "    if cnt > 1 & cnt % vol_break == 0:\n",
    "        volume = int(cnt / vol_break)\n",
    "        book.save()\n",
    "        \n",
    "        first_webpage.add_booktitle = str(volume)\n",
    "        book = Book(first_webpage)\n",
    "        \n",
    "    time.sleep(random.randint(1, 4))\n",
    "    cnt += 1\n",
    "    \n",
    "    # add webpage to book\n",
    "    webpage = Webpage(url, base_url)\n",
    "    book.add_chap(webpage)\n",
    "\n",
    "\n",
    "    # get next url\n",
    "    if page_limit == 1: break\n",
    "    try:\n",
    "        next_url = webpage.next_url\n",
    "        url = next_url\n",
    "    except:\n",
    "        print(\"End of url\")\n",
    "        break\n",
    "        \n",
    "book.save()\n",
    "print(\"DONE\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert False, \"breakpoint\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "webpage = Webpage(url, base_url)\n",
    "print(webpage.content)\n",
    "# webpage.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(webpage.soup.find('div', class_=re.compile('cont')).get_text(\"\\n\"))\n",
    "# webpage.soup.find('div', class_=re.compile('cont')).get_text(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
