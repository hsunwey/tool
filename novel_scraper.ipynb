{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import re\n",
    "from bs4 import BeautifulSoup\n",
    "import time\n",
    "import random\n",
    "from ebooklib import epub #http://docs.sourcefabric.org/projects/ebooklib/en/latest/tutorial.html#creating-epub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class Page:\n",
    "    def __init__(self, url, base_url):\n",
    "        self.url = url\n",
    "        self.base_url = base_url\n",
    "        req = requests.get(self.url, headers)\n",
    "        self.soup = BeautifulSoup(req.content)\n",
    "        \n",
    "    def get_next_url(self):\n",
    "        next_url = self.soup.find('a', string=re.compile(css_nexttext))['href']\n",
    "        next_url = base_url + next_url\n",
    "        return next_url\n",
    "\n",
    "    def get_booktitle(self):\n",
    "        \"\"\"soup.find('span', class_='shuming')\"\"\"\n",
    "        title = self.soup.find(**css_booktitle).text\n",
    "        title = self.clean_text(title)\n",
    "        return title\n",
    "\n",
    "    def get_author(self):\n",
    "        \"\"\"soup.find('h1', id='timu')\"\"\"\n",
    "        author = self.soup.find(**css_author).text\n",
    "        author = self.clean_text(author)\n",
    "        return author\n",
    "    \n",
    "    def get_chaptitle(self):\n",
    "        \"\"\"soup.find('h1', id='timu')\"\"\"\n",
    "        title = self.soup.find(**css_chaptitle).text\n",
    "        title = self.clean_text(title)\n",
    "        return title\n",
    "    \n",
    "    def get_content(self):\n",
    "        \"\"\"soup.find('h1', id='timu')\"\"\"\n",
    "        # find all 'p'\n",
    "        # content = self.soup.find_all(**css_content)\n",
    "        # content = [x.get_text() for x in content]\n",
    "        # content = '\\n'.join(content)\n",
    "        content = self.soup.find('div', class_=re.compile('cont')).text\n",
    "        \n",
    "        # clean\n",
    "        content = content.strip()\n",
    "        content = content.replace('\\u3000', '\\n')\n",
    "        content = content.replace('\\xa0', '\\n')\n",
    "        content = content.replace('<br/>', '\\n')\n",
    "        content = re.sub(r'\\n+', '\\n', content)\n",
    "        content = '\\t'.join(('\\n'+content.lstrip()).splitlines(keepends=True))\n",
    "        \n",
    "        # add chaptitle\n",
    "        chaptitle = self.get_chaptitle()\n",
    "        print(chaptitle, len(content))\n",
    "        content = chaptitle + '\\n' + content\n",
    "        \n",
    "        # html\n",
    "        content = content.replace('\\n', '<br>').replace('\\t', '&emsp;')\n",
    "        return content\n",
    "        \n",
    "    def clean_text(self, text):\n",
    "        text = text.replace('小說', '')\n",
    "        text = text.replace('作者', '')\n",
    "        text = text.replace('：', ' ')\n",
    "        text = text.replace(':', ' ')\n",
    "        text = re.sub(r' +', ' ', text)\n",
    "        text = text.strip()\n",
    "        return text\n",
    "    \n",
    "def run_test():\n",
    "    page = Page(url, base_url)\n",
    "    print('Booktitle:\\t', page.get_booktitle())\n",
    "    print('Author:\\t\\t', page.get_author())\n",
    "    print('chap:\\t', page.get_chaptitle())\n",
    "    print('Next url:\\t', page.get_next_url())\n",
    "    print('Content length:\\t', len(page.get_content()))\n",
    "    # print(page.get_content())\n",
    "    \n",
    "def create_book(first_page, language='zh'):\n",
    "    booktitle = first_page.get_booktitle()\n",
    "    print('Booktitle:', booktitle)\n",
    "\n",
    "    # define book\n",
    "    book = epub.EpubBook()\n",
    "    book.set_title(booktitle)\n",
    "    book.set_language(language)\n",
    "    try:\n",
    "        author = first_page.get_author()\n",
    "        print('Author:', author)\n",
    "        book.add_author(author)\n",
    "    except:\n",
    "        print('No author added')\n",
    "    return book\n",
    "\n",
    "def create_chap(page):\n",
    "    chaptitle = page.get_chaptitle()\n",
    "    chap = epub.EpubHtml(title=chaptitle, file_name=chaptitle + '.xhtml')\n",
    "    chap.set_content(page.get_content())\n",
    "    # chap.content = content\n",
    "    return chap\n",
    "\n",
    "def write_book(book, booktitle, toc, spine):\n",
    "    # toc\n",
    "    toc = tuple(toc)\n",
    "    book.toc = toc\n",
    "\n",
    "    # add default NCX and Nav file\n",
    "    book.add_item(epub.EpubNcx())\n",
    "    book.add_item(epub.EpubNav())\n",
    "\n",
    "    # spine = tuple(spine)\n",
    "    book.spine = ['nav', *spine]\n",
    "\n",
    "    # write to the file\n",
    "    epub.write_epub('book/' + booktitle + '.epub', book, {})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count = 0\n",
    "url = \"\"\"\n",
    "https://tw.uukanshu.com/b/150317/10451.html\n",
    "\"\"\"\n",
    "url = url.strip()\n",
    "base_url = 'https://tw.uukanshu.com'\n",
    "\n",
    "# css\n",
    "css_booktitle    = {'name': 'span', 'class_': 'shuming'}\n",
    "css_author       = {'name': 'span', 'class_': 'author'}\n",
    "css_chaptitle = {'name': 'h1', 'id': 'timu'}\n",
    "css_content      = {'name': 'p'}\n",
    "css_nexttext    = '下一章'\n",
    "\n",
    "# optional\n",
    "language = 'zh'\n",
    "file_format = \"epub\"\n",
    "\n",
    "headers = {\n",
    "    'Access-Control-Allow-Origin': '*',\n",
    "    'Access-Control-Allow-Methods': 'GET',\n",
    "    'Access-Control-Allow-Headers': 'Content-Type',\n",
    "    'Access-Control-Max-Age': '3600',\n",
    "    'User-Agent': 'Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:52.0) Gecko/20100101 Firefox/52.0'\n",
    "    }\n",
    "\n",
    "run_test()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save book"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "first_page = Page(url, base_url)\n",
    "booktitle = first_page.get_booktitle()\n",
    "continue_extract = True\n",
    "counter = 0\n",
    "\n",
    "\"\"\"\n",
    "declare file format\n",
    "\"\"\"\n",
    "if file_format == 'epub':\n",
    "    book = create_book(first_page, language=language)\n",
    "    # define toc\n",
    "    toc = []\n",
    "    spine = []\n",
    "else:\n",
    "    filename = booktitle + \".txt\"\n",
    "    f = open(filename, \"a+\")\n",
    "\n",
    "\"\"\"\n",
    "start scraping\n",
    "\"\"\"\n",
    "while url is not None and continue_extract and (counter < count or count == 0):\n",
    "    counter += 1\n",
    "    time.sleep(random.randint(3, 6))\n",
    "    \n",
    "    page = Page(url, base_url)\n",
    "    \n",
    "    # save as epub or txt file\n",
    "    if file_format == 'epub':\n",
    "        chap = create_chap(page)\n",
    "\n",
    "        # add chap\n",
    "        book.add_item(chap)\n",
    "        spine.append(chap)\n",
    "        # create toc\n",
    "        link = epub.Link(chap.file_name, chap.title, chap.id)\n",
    "        toc.append(link)\n",
    "    else:\n",
    "        f.write(page.get_content())\n",
    "\n",
    "    # get next url\n",
    "    try:\n",
    "        next_url = page.get_next_url()\n",
    "        url = next_url\n",
    "    except:\n",
    "        print(\"End of url\")\n",
    "        break\n",
    "        \n",
    "\"\"\"\n",
    "save file\n",
    "\"\"\"\n",
    "if file_format == 'epub':\n",
    "    write_book(book, booktitle, toc, spine)\n",
    "else:\n",
    "    f.close()\n",
    "    \n",
    "print(\"=====\\nDONE\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "page = Page(url, base_url)\n",
    "print(page.get_content())\n",
    "# page.get_content()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "page.soup.find('div', class_=re.compile('cont')).text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
